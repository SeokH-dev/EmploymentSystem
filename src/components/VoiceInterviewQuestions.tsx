import { useCallback, useEffect, useRef, useState } from 'react';
import { Button } from './ui/button';
import { Card } from './ui/card';
import { Progress } from './ui/progress';
import { Badge } from './ui/badge';
import { ArrowLeft, ArrowRight, MessageCircle, Mic, Play, Volume2 } from 'lucide-react';
import { CircularTimer } from './CircularTimer';
import { submitInterviewVoiceAnswer } from '../api/services/interviewService';
import type { Page, InterviewSession, NextQuestionResponse, InterviewCompletedResponse } from '../types';

const TOTAL_QUESTIONS = 10;

const isInterviewCompletedResponse = (
  response: NextQuestionResponse | InterviewCompletedResponse,
): response is InterviewCompletedResponse => {
  return 'questions' in response;
};

interface VoiceInterviewQuestionsProps {
  session: InterviewSession | null;
  onNavigate: (page: Page) => void;
  onComplete: (session: InterviewSession) => void;
}

type RecordingState = 'idle' | 'recording' | 'paused' | 'completed';

export function VoiceInterviewQuestions({ session, onNavigate, onComplete }: VoiceInterviewQuestionsProps) {
  const [currentQuestionIndex, setCurrentQuestionIndex] = useState(0);
  const [timeLeft, setTimeLeft] = useState(60);
  const [isTimerActive, setIsTimerActive] = useState(false);
  const [recordingState, setRecordingState] = useState<RecordingState>('idle');
  const [recordings, setRecordings] = useState<Blob[]>([]);
  const recordingsRef = useRef<Blob[]>([]);
  const [isQuestionPlaying, setIsQuestionPlaying] = useState(false);
  const [isPlayingRecording, setIsPlayingRecording] = useState(false);
  const [recordingUrls, setRecordingUrls] = useState<string[]>([]);
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const [sessionState, setSessionState] = useState<InterviewSession | null>(session);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const speechUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const recordingStreamRef = useRef<MediaStream | null>(null);
  const questionAudioRef = useRef<HTMLAudioElement | null>(null);

  const hasStartedFirstQuestionRef = useRef(false);

  const pendingSubmitRef = useRef<((recording: Blob | null) => void) | null>(null);

  useEffect(() => {
    if (!session) {
      hasStartedFirstQuestionRef.current = false;
      pendingSubmitRef.current = null;
      recordingsRef.current = [];
      setSessionState(null);
      setCurrentQuestionIndex(0);
      setRecordingState('idle');
      setTimeLeft(60);
      setIsTimerActive(false);
      setRecordings([]);
      recordingsRef.current = [];
      setRecordingUrls([]);
      setIsQuestionPlaying(false);
      setIsPlayingRecording(false);
      return;
    }

    hasStartedFirstQuestionRef.current = false;
    pendingSubmitRef.current = null;

    setSessionState({
      ...session,
      questions: session.questions.map((q, index) => ({
        ...q,
        questionNumber: q.questionNumber ?? index + 1,
      })),
    });
    setCurrentQuestionIndex(0);
    setRecordingState('idle');
    setTimeLeft(60);
    setIsTimerActive(false);
    setRecordings([]);
    recordingsRef.current = [];
    setRecordingUrls([]);
    setError(null);
  }, [session]);

  const hasSession = sessionState !== null;
  const currentQuestion = hasSession ? sessionState.questions[currentQuestionIndex] : null;
  const currentQuestionNumber = currentQuestion?.questionNumber ?? currentQuestionIndex + 1;
  const progress = hasSession ? (currentQuestionNumber / TOTAL_QUESTIONS) * 100 : 0;
  const questionPrompt = currentQuestion?.question && currentQuestion.question.trim().length > 0
    ? currentQuestion.question
    : currentQuestion?.audioUrl
      ? 'ì§ˆë¬¸ ìŒì„±ì„ ì¬ìƒí•´ ì£¼ì„¸ìš”.'
      : 'ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';


const currentRecordingBlob = recordings[currentQuestionIndex] ?? recordingsRef.current[currentQuestionIndex] ?? null;


  // ìŒì„± ë©´ì ‘ ì§„í–‰ ìƒíƒœ ë¡œê·¸ (ì§ˆë¬¸ ë³€ê²½ ì‹œì—ë§Œ ì‹¤í–‰)
  useEffect(() => {
    if (!sessionState) return;

    console.log('ğŸ” ìŒì„± ë©´ì ‘ ì§„í–‰ ìƒíƒœ:', {
      questionNumber: currentQuestionNumber,
      currentQuestionIndex,
      progress: Math.round(progress),
      sessionQuestionsLength: sessionState.questions.length
    });
  }, [currentQuestionNumber, sessionState, progress, currentQuestionIndex]);

  // ë…¹ìŒ URL ìƒì„±
  useEffect(() => {
    const urls = recordings.map(recording => 
      recording ? URL.createObjectURL(recording) : ''
    );
    setRecordingUrls(urls);

    // ì´ì „ URLë“¤ ì •ë¦¬
    return () => {
      urls.forEach(url => {
        if (url) URL.revokeObjectURL(url);
      });
    };
  }, [recordings]);






const playQuestionAndStartRecording = useCallback(async (questionText: string) => {
  if (!currentQuestion) {
    return;
  }

  if (recordingState === 'recording' || isQuestionPlaying) {
    setError('ë…¹ìŒì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ë…¹ìŒì„ ì¢…ë£Œí•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    return;
  }

  setError(null);
  pendingSubmitRef.current = null;

  if (speechUtteranceRef.current) {
    speechSynthesis.cancel();
    speechUtteranceRef.current = null;
  }

  const startRecording = async (targetIndex: number) => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recordingStreamRef.current = stream;

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      const chunks: BlobPart[] = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = chunks.length > 0 ? new Blob(chunks, { type: 'audio/webm' }) : null;

        if (blob) {
          setRecordings((prev) => {
            const updated = [...prev];
            updated[targetIndex] = blob;
            recordingsRef.current = updated;
            return updated;
          });
        }

        const submitAfterStop = pendingSubmitRef.current;
        pendingSubmitRef.current = null;

        if (recordingStreamRef.current) {
          recordingStreamRef.current.getTracks().forEach((track) => track.stop());
          recordingStreamRef.current = null;
        }

        if (submitAfterStop) {
          submitAfterStop(blob);
        }
      };

      mediaRecorder.start();
      setRecordingState('recording');
      setIsTimerActive(true);
    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  const audioUrl = currentQuestion.audioUrl;
  const targetIndex = currentQuestionIndex;

  if (audioUrl) {
    try {
      if (questionAudioRef.current) {
        questionAudioRef.current.pause();
        questionAudioRef.current = null;
      }

      const audio = new Audio(audioUrl);
      questionAudioRef.current = audio;

      audio.onplay = () => {
        setIsQuestionPlaying(true);
      };

      audio.onended = async () => {
        questionAudioRef.current = null;
        setIsQuestionPlaying(false);
        await startRecording(targetIndex);
      };

      audio.onerror = () => {
        questionAudioRef.current = null;
        setIsQuestionPlaying(false);
        console.error('ì§ˆë¬¸ ìŒì„± ì¬ìƒ ì‹¤íŒ¨: ', audioUrl);
        setError('ì§ˆë¬¸ ìŒì„±ì„ ì¬ìƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.');
        speechSynthesis.cancel();
        speechUtteranceRef.current = null;
        if (questionText) {
          const utterance = new SpeechSynthesisUtterance(questionText);
          utterance.lang = 'ko-KR';
          utterance.rate = 0.8;
          utterance.pitch = 1;

          speechUtteranceRef.current = utterance;

          utterance.onstart = () => {
            setIsQuestionPlaying(true);
          };

          utterance.onend = () => {
            setIsQuestionPlaying(false);
            startRecording(targetIndex);
          };

          speechSynthesis.speak(utterance);
        }
      };

      await audio.play();
      return;
    } catch {
      setError('ì§ˆë¬¸ ìŒì„±ì„ ì¬ìƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.');
      questionAudioRef.current = null;
    }
  }

  if (!audioUrl && !questionText) {
    setError('ì§ˆë¬¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
    return;
  }

  try {
    const utterance = new SpeechSynthesisUtterance(questionText);
    utterance.lang = 'ko-KR';
    utterance.rate = 0.8;
    utterance.pitch = 1;

    speechUtteranceRef.current = utterance;

    utterance.onstart = () => {
      setIsQuestionPlaying(true);
    };

    utterance.onend = () => {
      setIsQuestionPlaying(false);
      startRecording(targetIndex);
    };

    speechSynthesis.speak(utterance);
  } catch (error) {
    console.error('ìŒì„± í•©ì„± ì‹¤íŒ¨:', error);
    setError('ìŒì„± ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}, [currentQuestion, currentQuestionIndex, isQuestionPlaying, recordingState]);

const stopRecording = useCallback(() => {
    if (speechUtteranceRef.current) {
      speechSynthesis.cancel();
      setIsQuestionPlaying(false);
      speechUtteranceRef.current = null;
    }

    if (questionAudioRef.current) {
      questionAudioRef.current.pause();
      questionAudioRef.current.currentTime = 0;
      questionAudioRef.current = null;
      setIsQuestionPlaying(false);
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      setRecordingState('completed');
      setIsTimerActive(false);
    }
  }, []);

  const pauseRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.pause();
      setRecordingState('paused');
      setIsTimerActive(false);
    }
  }, []);

  const resumeRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'paused') {
      mediaRecorderRef.current.resume();
      setRecordingState('recording');
      setIsTimerActive(true);
    }
  }, []);

  
const proceedToNext = useCallback(async (overrideRecording?: Blob | null) => {
    if (!sessionState || !currentQuestion) return;

    setIsSubmitting(true);
    setError(null);

    try {
      const currentRecording = overrideRecording ?? recordings[currentQuestionIndex] ?? recordingsRef.current[currentQuestionIndex];
      if (!currentRecording) {
        setError('ë…¹ìŒì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë‹µë³€ì„ ë…¹ìŒí•´ì£¼ì„¸ìš”.');
        return;
      }

      const elapsedSeconds = Math.max(60 - timeLeft, 0);

      const requestPayload = {
        persona_id: sessionState.personaId,
        interview_session_id: sessionState.id,
        question_id: currentQuestion.id,
        question_number: currentQuestion.questionNumber,
        audio_file: currentRecording,
        time_taken: elapsedSeconds
      };

      const response = await submitInterviewVoiceAnswer(requestPayload);

      if (isInterviewCompletedResponse(response)) {
        const completedSession: InterviewSession = {
          ...sessionState,
          score: response.score,
          grade: response.grade,
          status: response.status,
          totalQuestions: response.total_questions,
          totalTime: response.total_time,
          averageAnswerTime: response.average_answer_time,
          averageAnswerLength: response.average_answer_length,
          questions: response.questions.map((q) => ({
            id: q.question_id,
            questionNumber: q.question_number,
            question: q.question_text ?? '',
            audioUrl: q.audio_url,
            answer: q.answer_text,
            type: q.question_type as 'job-knowledge' | 'ai-recommended' | 'cover-letter',
            timeSpent: q.time_taken
          })),
          feedback: {
            strengths: response.final_good_points,
            improvements: response.final_improvement_points,
            suggestions: []
          },
          completedAt: response.completed_at
        };

        onComplete(completedSession);
      } else {
        setSessionState((prev) => {
          if (!prev) return prev;

          const questionsWithAnswer = prev.questions.map((question, index) =>
            index === currentQuestionIndex
              ? {
                  ...question,
                  answer: question.answer || 'ìŒì„± ë‹µë³€ ì œì¶œ ì™„ë£Œ',
                  timeSpent: elapsedSeconds
                }
              : question
          );

          questionsWithAnswer.push({
            id: response.question_id,
            questionNumber: response.question_number,
            question: response.question_text ?? '',
            audioUrl: response.audio_url,
            answer: '',
            type: response.question_type as 'job-knowledge' | 'ai-recommended' | 'cover-letter',
            timeSpent: 0
          });

          return {
            ...prev,
            questions: questionsWithAnswer
          };
        });

        setCurrentQuestionIndex((prev) => prev + 1);
        setTimeLeft(60);
        setIsTimerActive(false);
        setRecordingState('idle');

        setTimeout(() => {
          playQuestionAndStartRecording(response.question_text ?? '');
        }, 1000);
      }
    } catch {
      setError('ë‹µë³€ ì œì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsSubmitting(false);
    }
  }, [currentQuestion, currentQuestionIndex, playQuestionAndStartRecording, recordings, sessionState, timeLeft, onComplete]);

  const handleNextQuestion = useCallback(() => {
    if (!currentQuestion) return;

    if (recordingState === 'recording') {
      pendingSubmitRef.current = (blob) => {
        if (!blob) {
          setError('ë…¹ìŒì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
          return;
        }
        proceedToNext(blob);
      };
      stopRecording();
      return;
    }

    if (recordingState !== 'completed') {
      setError('ë¨¼ì € ë‹µë³€ì„ ë…¹ìŒí•´ì£¼ì„¸ìš”.');
      return;
    }

    proceedToNext();
  }, [currentQuestion, proceedToNext, recordingState, stopRecording]);


const playRecording = (recordingIndex: number) => {
  const urlFromState = recordingUrls[recordingIndex];
  const blob = recordingsRef.current[recordingIndex] ?? recordings[recordingIndex];

  if (!urlFromState && !blob) {
    setError('ì¬ìƒí•  ë…¹ìŒì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒí•´ì£¼ì„¸ìš”.');
    return;
  }

  const playbackUrl = urlFromState ?? URL.createObjectURL(blob as Blob);
  setIsPlayingRecording(true);
  const audio = new Audio(playbackUrl);

  audio.onended = () => {
    setIsPlayingRecording(false);
    if (!urlFromState && blob) {
      URL.revokeObjectURL(playbackUrl);
    }
  };

  audio.onerror = () => {
    setIsPlayingRecording(false);
    if (!urlFromState && blob) {
      URL.revokeObjectURL(playbackUrl);
    }
    console.error('ë…¹ìŒ ì¬ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  };

  audio.play().catch(error => {
    setIsPlayingRecording(false);
    if (!urlFromState && blob) {
      URL.revokeObjectURL(playbackUrl);
    }
    console.error('ë…¹ìŒ ì¬ìƒ ì‹¤íŒ¨:', error);
  });
};

  



  // íƒ€ì´ë¨¸ íš¨ê³¼
  useEffect(() => {
    let interval: ReturnType<typeof setInterval> | undefined;

    if (isTimerActive && timeLeft > 0) {
      interval = setInterval(() => {
        setTimeLeft((prev) => {
          if (prev <= 1) {
            if (recordingState === 'recording') {
              pendingSubmitRef.current = (blob) => {
                if (!blob) {
                  setError('ë…¹ìŒì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                  return;
                }
                proceedToNext(blob);
              };
              stopRecording();
            }
            return 0;
          }
          return prev - 1;
        });
      }, 1000);
    }

    return () => {
      if (interval) clearInterval(interval);
    };
  }, [isTimerActive, proceedToNext, recordingState, timeLeft, stopRecording]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì²« ì§ˆë¬¸ ì¬ìƒ ë° ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (!currentQuestion) return;

    if (currentQuestionIndex === 0 && !hasStartedFirstQuestionRef.current) {
      hasStartedFirstQuestionRef.current = true;
      const timer = setTimeout(() => {
        playQuestionAndStartRecording(currentQuestion.question || questionPrompt);
      }, 1000);

      return () => clearTimeout(timer);
    }
  }, [currentQuestion, currentQuestionIndex, playQuestionAndStartRecording, questionPrompt]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (speechUtteranceRef.current) {
        speechSynthesis.cancel();
      }
      if (questionAudioRef.current) {
        questionAudioRef.current.pause();
        questionAudioRef.current = null;
      }
      if (recordingStreamRef.current) {
        recordingStreamRef.current.getTracks().forEach(track => track.stop());
      }
      recordingUrls.forEach(url => {
        if (url) URL.revokeObjectURL(url);
      });
    };
  }, [recordingUrls]);

  if (!hasSession || !currentQuestion) {
    return (
      <div className="min-h-screen bg-gray-50 flex items-center justify-center">
        <div className="text-center">
          <MessageCircle className="h-12 w-12 text-gray-400 mx-auto mb-4" />
          <h2 className="text-xl font-semibold mb-2">ë©´ì ‘ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</h2>
          <p className="text-gray-600 mb-6">
            ë©´ì ‘ ì—°ìŠµì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”
          </p>
          <Button onClick={() => onNavigate('interview-practice')}>
            ë©´ì ‘ ì—°ìŠµ ì‹œì‘í•˜ê¸°
          </Button>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gray-50">
      {/* Header */}
      <header className="bg-white border-b border-gray-200 px-6 py-2">
        <div className="max-w-6xl mx-auto flex items-center justify-between">
            <Button
              variant="ghost"
              size="sm"
            onClick={() => onNavigate('interview-practice')}
              className="flex items-center space-x-2"
            >
              <ArrowLeft className="h-4 w-4" />
            <span>ë©´ì ‘ ì—°ìŠµ</span>
            </Button>

          <div className="flex items-center space-x-4">
            <div className="text-sm text-gray-600">
              ì§ˆë¬¸ {currentQuestionNumber} / {TOTAL_QUESTIONS}
            </div>
            <Progress value={progress} className="w-32" />
          </div>

          <div className="w-20" />
        </div>
      </header>

      {/* Main Content */}
      <main className="px-6 py-8">
        <div className="max-w-6xl mx-auto grid lg:grid-cols-3 gap-8">
          {/* Question Section - 2 columns */}
          <div className="lg:col-span-2">
              <Card className="p-8">
                <div className="space-y-6">
                  {/* Question Header */}
                <div className="flex items-center space-x-3">
                  <div className="w-8 h-8 bg-blue-100 rounded-full flex items-center justify-center">
                    <MessageCircle className="h-4 w-4 text-blue-600" />
                  </div>
                  <Badge variant="secondary">{currentQuestion.type}</Badge>
                </div>

                {/* Question Text */}
                <div className="space-y-4">
                  <h2 className="text-xl font-semibold text-gray-900 leading-relaxed">
                      {questionPrompt}
                  </h2>
                  
                  {/* Question Play Button */}
                  <div className="flex items-center space-x-3">
                    <Button
                      variant="outline"
                      size="sm"
                      onClick={() => {
                        if (recordingState === 'recording') {
                          setError('ë…¹ìŒ ì¤‘ì—ëŠ” ì§ˆë¬¸ì„ ë‹¤ì‹œ ë“¤ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                          return;
                        }

                        if (speechUtteranceRef.current) {
                          speechSynthesis.cancel();
                          speechUtteranceRef.current = null;
                        }
                        if (questionAudioRef.current) {
                          questionAudioRef.current.pause();
                          questionAudioRef.current.currentTime = 0;
                          questionAudioRef.current = null;
                        }
                        playQuestionAndStartRecording(currentQuestion.question || questionPrompt);
                      }}
                      disabled={isQuestionPlaying || recordingState === 'recording'}
                    >
                      <Volume2 className="h-4 w-4 mr-2" />
                      {isQuestionPlaying ? 'ì¬ìƒ ì¤‘...' : 'ì§ˆë¬¸ ë‹¤ì‹œ ë“£ê¸°'}
                    </Button>
                  </div>
                </div>

                {/* Recording Controls */}
                <div className="space-y-4">
                  <div className="flex items-center space-x-4">
                    {recordingState === 'idle' && (
                      <Button
                        onClick={() => {
                          if (speechUtteranceRef.current) {
                            speechSynthesis.cancel();
                            speechUtteranceRef.current = null;
                          }
                          if (questionAudioRef.current) {
                            questionAudioRef.current.pause();
                            questionAudioRef.current.currentTime = 0;
                            questionAudioRef.current = null;
                          }
                          playQuestionAndStartRecording(currentQuestion.question || questionPrompt);
                        }}
                        disabled={isQuestionPlaying || recordingState === 'recording'}
                        className="bg-red-600 hover:bg-red-700"
                      >
                        <Mic className="h-4 w-4 mr-2" />
                        ë…¹ìŒ ì‹œì‘
                      </Button>
                    )}

                    {recordingState === 'recording' && (
                      <>
                        <Button
                          onClick={pauseRecording}
                          variant="outline"
                          className="border-yellow-500 text-yellow-600 hover:bg-yellow-50"
                        >
                          ì¼ì‹œì •ì§€
                        </Button>
                        <Button
                          onClick={stopRecording}
                          className="bg-red-600 hover:bg-red-700"
                        >
                          ë…¹ìŒ ì™„ë£Œ
                        </Button>
                      </>
                    )}

                    {recordingState === 'paused' && (
                      <>
                        <Button
                          onClick={resumeRecording}
                          className="bg-green-600 hover:bg-green-700"
                        >
                          ì¬ê°œ
                        </Button>
                        <Button
                          onClick={stopRecording}
                          className="bg-red-600 hover:bg-red-700"
                        >
                          ë…¹ìŒ ì™„ë£Œ
                        </Button>
                          </>
                        )}

                    {recordingState === 'completed' && currentRecordingBlob && (
                      <div className="flex items-center space-x-3">
                        <Button
                          variant="outline"
                          onClick={() => playRecording(currentQuestionIndex)}
                          disabled={isPlayingRecording}
                        >
                          <Play className="h-4 w-4 mr-2" />
                          {isPlayingRecording ? 'ì¬ìƒ ì¤‘...' : 'ë‹µë³€ ë“£ê¸°'}
                        </Button>
                        <span className="text-sm text-green-600 font-medium">
                          âœ“ ë‹µë³€ì´ ë…¹ìŒë˜ì—ˆìŠµë‹ˆë‹¤
                        </span>
                      </div>
                    )}
                  </div>

                  {/* Recording Status */}
                  <div className="text-sm text-gray-600">
                    {recordingState === 'recording' && (
                      <span className="text-red-600 font-medium">â— ë…¹ìŒ ì¤‘...</span>
                    )}
                    {recordingState === 'paused' && (
                      <span className="text-yellow-600 font-medium">â¸ ì¼ì‹œì •ì§€ë¨</span>
                    )}
                    {recordingState === 'completed' && (
                      <span className="text-green-600 font-medium">âœ“ ë…¹ìŒ ì™„ë£Œ</span>
                    )}
                  </div>
                  </div>

                  {/* Action Buttons */}
                  <div className="flex justify-end pt-4">
                    <Button
                      onClick={handleNextQuestion}
                    disabled={isQuestionPlaying || isSubmitting}
                      className="bg-black hover:bg-gray-800"
                    >
                    {isSubmitting ? 'ë‹µë³€ ì œì¶œ ì¤‘...' : (currentQuestionNumber === TOTAL_QUESTIONS ? 'ë©´ì ‘ ì™„ë£Œ' : 'ë‹µë³€ ì™„ë£Œ')}
                      <ArrowRight className="h-4 w-4 ml-2" />
                  </Button>
                  
                  {error && (
                    <div className="mt-4 p-4 bg-red-50 border border-red-200 rounded-lg">
                      <p className="text-red-600 text-sm">{error}</p>
                      <Button 
                        variant="outline" 
                        size="sm" 
                        onClick={() => setError(null)}
                        className="mt-2"
                      >
                        ë‹«ê¸°
                    </Button>
                    </div>
                  )}
                  </div>
                </div>
              </Card>
            </div>

            {/* Timer Section - 1 column */}
            <div className="lg:col-span-1">
              <Card className="p-6 sticky top-8">
                <div className="text-center space-y-4">
                  <h3 className="font-semibold text-gray-700">ë‚¨ì€ ì‹œê°„</h3>

                  <div className="flex justify-center">
                    <CircularTimer
                      timeLeft={timeLeft}
                      totalTime={60}
                      isActive={isTimerActive}
                    size={120}
                    />
                  </div>

                <div className="text-sm text-gray-600">
                  {timeLeft > 0 ? `${timeLeft}ì´ˆ ë‚¨ìŒ` : 'ì‹œê°„ ì¢…ë£Œ'}
                  </div>

                <div className="space-y-2">
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={() => setIsTimerActive(!isTimerActive)}
                    disabled={recordingState === 'completed'}
                    className="w-full"
                  >
                    {isTimerActive ? 'ì¼ì‹œì •ì§€' : 'ì¬ì‹œì‘'}
                  </Button>
                </div>
                </div>
              </Card>
          </div>
        </div>
      </main>
    </div>
  );
}